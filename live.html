<!DOCTYPE html>
<html lang="en">
<head>
    <title>webvr live-video</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <style>
        body {
            font-family: Monospace;
            background-color: #f0f0f0;
            margin: 0px;
            overflow: hidden;
        }
        #info {
            position: absolute;
            top: 10px;
            width: 100%;
            color: #fff;
            text-align: center;
        }
        a {
            color: #ff0
        }
    </style>
</head>
<body>
<div id="container"></div>
<!--
<div id="info">
	<a href="http://threejs.org" target="_blank">three.js</a> webgl - vr video<br />
	stereoscopic panoramic render by <a href="http://pedrofe.com/rendering-for-oculus-rift-with-arnold/" target="_blank">pedrofe</a>. scene from <a href="http://www.meryproject.com/" target="_blank">mery project</a>.
</div>
-->

<script src="static/js/three.js"></script>

<script src="static/js/VREffect.js"></script>
<script src="static/js/VRControls.js"></script>
<!-- A polyfill for the WebVR API.  -->
<script src="static/js/webvr-polyfill.js"></script>
<!-- 特效 -->
<script src="static/js/texiao.js"></script>
<!-- 视控 -->
<script src="static/js/EyeControls.js"></script>
<!-- 菜单 -->
<script src="static/js/vr_menu.js"></script>
<!-- 图形 -->
<script src="static/js/Geometry.js"></script>
<script src="static/js/HControl.js"></script>
<!-- 图像识别-->
<script src="static/js/CvControls.js"></script>
<script src="static/js/device.js"></script>
<script src="static/js/JSARToolKit.js"></script>
<script src="static/js/magi.js"></script>


<script type="text/javascript">
    var user = false;

    var camera, scene, renderer;
    var video, texture;

    var controls, effect;
    var eye_controler;
    var menu;
    var hc = new HControl();     //头势控制&&菜单随动
    var thing;
    var ws;
    var ambientLight;
    var font;
    var loader = new THREE.FontLoader();
    loader.load( 'static/json/FZYaoTi_Regular.json', function ( response ) {
        font = response;
    } );
    var voice_status = false;

    /**
     * @author mrdoob / http://mrdoob.com
     * Based on @tojiro's vr-samples-utils.js
     */

    var vrDisplay;
    var WEBVR = {

        isLatestAvailable: function () {

            return navigator.getVRDisplays !== undefined;

        },

        isAvailable: function () {

            return navigator.getVRDisplays !== undefined || navigator.getVRDevices !== undefined;

        },

        getMessage: function () {

            var message;

            if ( navigator.getVRDisplays ) {

                navigator.getVRDisplays().then( function ( displays ) {

                    if ( displays.length === 0 ) message = 'WebVR supported, but no VRDisplays found.';

                } );

            } else if ( navigator.getVRDevices ) {

                message = 'Your browser supports WebVR but not the latest version. See <a href="http://webvr.info">webvr.info</a> for more info.';

            } else {

                message = 'Your browser does not support WebVR. See <a href="http://webvr.info">webvr.info</a> for assistance.';

            }

            if ( message !== undefined ) {

                var container = document.createElement( 'div' );
                container.style.position = 'absolute';
                container.style.left = '0';
                container.style.top = '0';
                container.style.right = '0';
                container.style.zIndex = '999';
                container.align = 'center';

                var error = document.createElement( 'div' );
                error.style.fontFamily = 'sans-serif';
                error.style.fontSize = '16px';
                error.style.fontStyle = 'normal';
                error.style.lineHeight = '26px';
                error.style.backgroundColor = '#fff';
                error.style.color = '#000';
                error.style.padding = '10px 20px';
                error.style.margin = '50px';
                error.style.display = 'inline-block';
                error.innerHTML = message;
                container.appendChild( error );

                return container;

            }

        },

        getButton: function () {

            var button = document.createElement( 'button' );
            button.style.position = 'absolute';
            button.style.left = 'calc(50% - 50px)';
            button.style.bottom = '20px';
            button.style.width = '100px';
            button.style.border = '0';
            button.style.padding = '8px';
            button.style.cursor = 'pointer';
            button.style.backgroundColor = '#000';
            button.style.color = '#fff';
            button.style.fontFamily = 'sans-serif';
            button.style.fontSize = '13px';
            button.style.fontStyle = 'normal';
            button.style.textAlign = 'center';
            button.style.zIndex = '999';
            button.textContent = 'ENTER VR';
            button.onclick = function() {
                console.log('vr model');
                //vrDisplay.isPresenting ? vrDisplay.exitPresent() : vrDisplay.requestPresent([{source: renderer.domElement}]);
                vrDisplay.requestPresent([{source: renderer.domElement}]);
                //init_webvr();

            };

            window.addEventListener( 'vrdisplaypresentchange', function ( event ) {

                button.textContent = effect.isPresenting ? 'EXIT VR' : 'ENTER VR';

            }, false );

            return button;

        }

    };



</script>

<script>

    if ( WEBVR.isLatestAvailable() === false ) {

        document.body.appendChild( WEBVR.getMessage() );

    }

    //

    init();
    animate();


    function init() {

        var container = document.getElementById( 'container' );
        container.addEventListener( 'click', function () {
            video.play();
        } );

        camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 1, 2000 );
        //camera.layers.enable( 1 ); // render left view when no stereo available
        eye_controler = new THREE.EyeControls(camera);
        // video

        video = document.createElement( 'video' );
        //print_video_event();
        //video.loop = true;
        //video.muted = true;

        //http://58.135.196.138:8090/live/789E9CE292A040d2A459CF55D2FB362E/789E9CE292A040d2A459CF55D2FB362E.m3u8

        //video.src = 'http://sohow.applinzi.com/static/img/sintel.mp4'
        //video.src = 'http://sohow.applinzi.com/static/img/MaryOculus.mp4';
        //video.src = 'http://sohow.applinzi.com/static/img/m1.mp4';
        //video.src = 'http://sohow.applinzi.com/static/img/hsy.mp4';
        //video.src = 'http://10.235.24.45/hls/test.m3u8';
        //video.src = 'http://58.135.196.138:8090/live/789E9CE292A040d2A459CF55D2FB362E/789E9CE292A040d2A459CF55D2FB362E.m3u8';
        //video.src = 'http://hls.yy.com/live/54880976_54880976.m3u8?id=yyent&uid=0d268e721bafa16011ed420182ecd1d81472019973&appid=15012&uuid=1A3512763E4046869071355677D1FD4A';
        //video.src = 'https://sohow.applinzi.com/static/video/v2.mp4';
        video.src = 'http://10.235.24.45/hls/test.m3u8';
        //video.src = 'static/video/zp.mp4';
        video.setAttribute('crossorigin', 'anonymous');
        //video.setAttribute( 'type', 'application/vnd.apple.mpegurl' );
        //video.setAttribute( 'type', 'application/x-mpegURL' );	//video/mp4
        video.setAttribute( 'webkit-playsinline', 'webkit-playsinline' );
        video.load();
        video.play();

        video.addEventListener('playing',function(){
            if (typeof window.cv_controler == "undefined") {
                window.cv_controler = new CvControls(video,null,camera);
            }
        });


        texture = new THREE.VideoTexture( video );
        texture.minFilter = THREE.NearestFilter;
        texture.maxFilter = THREE.NearestFilter;
        texture.format = THREE.RGBFormat;
        texture.generateMipmaps = false;

        scene = new THREE.Scene();

        material = new THREE.MeshLambertMaterial( { map: texture } );
        var mesh = new THREE.Mesh( get_geometry(), material );
        mesh.rotation.y = - Math.PI / 2;
        scene.add( mesh );

        //add_menu();
	    menu = new THREE.VrMenu();

        var is_play = false;
        var is_zan = false;
        menu.add_option(scene, eye_controler, 'static/img/love.png', function (obj) {
            if (!is_zan ){
                is_zan = true;
                zan(10);
                setTimeout(function(){is_zan = false},300*10);
            }
        });
        menu.add_option(scene, eye_controler, 'static/img/f.png', function (obj) {
//            var data= {title:"123",items:["11","22","33"]}
//            addBox(data);
//            playAudio("http://lizhilei.cn/webvr/static/audio/th.wav");
//            placeItem();
//            showTips('你好');
            if (!is_play ){
                is_play = true;
                texiao1();
                setTimeout(function(){is_play = false},1500)
            }
        });
        menu.add_option(scene, eye_controler, 'static/img/yl.png', function (obj) {
            if (!is_play ){
                is_play = true;
                texiao();
                setTimeout(function(){is_play = false},1000)
            }
        });

        menu.add_option(scene, eye_controler, 'static/img/voice.png', function (obj) {
            voice();
        });
        menu.show(scene,eye_controler);

        //

        renderer = new THREE.WebGLRenderer();
        renderer.setClearColor( 0x101010 );
        renderer.setPixelRatio( window.devicePixelRatio );
        renderer.setSize( window.innerWidth, window.innerHeight );
        container.appendChild( renderer.domElement );

        //

        controls = new THREE.VRControls( camera );

        effect = new THREE.VREffect( renderer );
        effect.scale = 0; // video doesn't need eye separation
        effect.setSize( window.innerWidth, window.innerHeight );

        if ( WEBVR.isAvailable() === true ) {
            // Get the VRDisplay and save it for later.
            navigator.getVRDisplays().then(function(displays) {
                if (displays.length > 0) {
                    vrDisplay = displays[0];
                }
            });
            document.body.appendChild( WEBVR.getButton(  ) );

        }

        ambientLight = new THREE.AmbientLight(0xffffff  );
        scene.add( ambientLight );
        hc.open();
        //
        window.addEventListener( 'resize', onWindowResize, false );


    }
    var is_voice_init = false;
    var is_voice_change = false;
    function voice() {
        var op;
        if(!is_voice_init) {
            open_voice();
            is_voice_init = true;
            is_voice_change = true;
            setTimeout(function() {
                is_voice_change = false;
            },10000);
            op = menu.options[3];
            voice_status = !voice_status;
            menu.change_pic(op,'static/img/novoice.png');
            menu.options[3].position.x = op.position.x;
            menu.options[3].position.y = op.position.y;
            menu.options[3].position.z = op.position.z;
            menu.options[3].rotation.x = op.rotation.x;
            menu.options[3].rotation.y = op.rotation.y;
            menu.options[3].rotation.z = op.rotation.z;
            menu.show(scene,eye_controler);
        }
        if (!is_voice_change){
            is_voice_change = true;
            setTimeout(function() {
                is_voice_change = false;
            },2000);
            if (1){
                voice_status = !voice_status;
                op = menu.options[3];
                if (voice_status){
			        console.log('start');
                    recognizer.postMessage({command: 'start'});
                    menu.change_pic(op,'static/img/novoice.png');
                } else {
			        console.log('stop');
                    recognizer.postMessage({command: 'stop'});
                    menu.change_pic(op,'static/img/voice.png');
                }
                menu.options[3].position.x = op.position.x;
                menu.options[3].position.y = op.position.y;
                menu.options[3].position.z = op.position.z;
                menu.options[3].rotation.x = op.rotation.x;
                menu.options[3].rotation.y = op.rotation.y;
                menu.options[3].rotation.z = op.rotation.z;
                menu.show(scene,eye_controler);
            }
        }




    }
    function playAudio(src) {
        var audio = new Audio();
        audio.src=src;
        audio.play();
        audio.addEventListener('ended',function(){
            audio = null;
        });

    }

    var item;
    function placeItem(data) {
        var     width =  100,
                height =  100,
                x =  300,
                y =  100,
                z =  0,
                pic = "static/img/9.png";
        if (typeof data != "undefined") {
            width =  data.width || 100;
            height =  data.height || 100;
            x =  data.x || 0;
            y =  data.y || 100;
            z =  data.z || -300;
            pic = data.pic || "static/img/9.png";
        }
        var radiu =  Math.sqrt(x * x + z * z);
        var ths = Math.asin(x / radiu);
        var thc = Math.acos(-z / radiu);
        console.log(ths);
        console.log(thc);
        var th;
        if (x >= 0 && z >= 0) {
            th = Math.acos(-z / radiu);
        } else if (x < 0 && z >= 0) {
            th = -Math.acos(-z / radiu);
        } else if (x >= 0 && z < 0) {
            th = Math.asin(x / radiu);
        } else if (x < 0 && z < 0) {
            th = Math.asin(x / radiu);
        }

        item = new THREE.VrMenu();
        item.menu_position.set(x, y, z);
        item.option_margin_x = width;
        item.option_height = height;
        item.option_width = width;
        item.add_option(scene, eye_controler, pic, function (obj) {
            if (ws != null || user !== false) {
                var msg = {
                    type : 'finditem',
                    uid : user
                };
                msg=JSON.stringify(msg);
                ws.send(msg);
            }
            delItem();
        });
        item.options[0].position.x = x;
        item.options[0].position.y = y;
        item.options[0].position.z = z;
        item.options[0].rotation.y = -th;
        item.show(scene,eye_controler);

    }
    function delItem() {
        item.remove_option(scene, eye_controler, item.options[0]);
    }
    function head(data) {
        var box;
        var textMesh;

        function clear(msg) {
            console.log(msg);
            if (ws != null || user !== false) {
                var msgs = {
                    type : 'head',
                    data : msg,
                    uid : user
                };
                msgs=JSON.stringify(msgs);
                ws.send(msgs);
            }
            hc.closeNod();
            hc.closeRock();
            scene.remove(textMesh);
        }

        if (data.title != ""){
            //开启头势
            setTimeout(function(){
                console.log('nod start');
                hc.setNod(function(){
                    var msg = "Nod";
                    clear(msg);
                });
                hc.setShook(function(){
                    var msg = "Shook";
                    clear(msg);
                });
            },2000);
            var p,r;
            var eulerZYX = hc.getEulerZYX();
            var eulerYXZ = hc.getEulerYXZ();
            var th = eulerYXZ.y;
            var e;
            p = {
                x:300 * Math.sin(th),
                y:50,
                z:-300 * Math.cos(th)
            };
            r = {
                x:0,
                y:-th,
                z:0
            };

            var textMaterial = new THREE.MultiMaterial( [
                new THREE.MeshPhongMaterial( { color: 0x000000, shading: THREE.FlatShading } ), // front
                new THREE.MeshPhongMaterial( { color: 0xffffff, shading: THREE.SmoothShading } ) // side
            ] );
            var textGeo = new THREE.TextGeometry( data.title, {
                font: font,
                size: 50,
                height: 20,
                curveSegments: 4,
                bevelThickness: 2,
                bevelSize: 1.5,
                bevelEnabled: true,
                material: 0,
                extrudeMaterial: 1
            });
            textGeo.computeBoundingBox();
            textGeo.computeVertexNormals();
            var centerOffset = -0.5 * ( textGeo.boundingBox.max.x - textGeo.boundingBox.min.x );

            textMesh = new THREE.Mesh( textGeo, textMaterial );
            textMesh.position.x = centerOffset + p.x;
            textMesh.position.y = p.y+50;
            textMesh.position.z = p.z;
            textMesh.rotation.x = r.x;
            textMesh.rotation.y = r.y;
            textMesh.rotation.z = r.z;

            scene.add(textMesh);
        }
    }

    function onWindowResize() {

        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();

        effect.setSize( window.innerWidth, window.innerHeight );

    }

    function addBox(data) {
        var box;
        var textMesh;
        function remove() {
            if (data.title != ""){
                scene.remove(textMesh);
            }

            var len = box.options.length;
            for(var i=0; i<len;i++){
                op = box.options[i];
                box.remove_option(scene, eye_controler, op);
            }
            len = box.options.length;
            for(i=0; i<len;i++){
                op = box.options[i];
                box.remove_option(scene, eye_controler, op);
            }

        }

        box = new THREE.VrMenu();
        box.menu_position.set(0, -50, -300);
        box.option_margin_x = 100;
        for(var i=0;i<data.items.length;i++){
            var ms = data.items[i];
            box.add_text_option(scene, eye_controler, ms, function (obj) {
                console.log(obj.name);
                if (ws != null || user !== false) {
                    var msg = {
                        type : 'selectmenu',
                        data : obj.name,
                        uid : user
                    };
                    msg=JSON.stringify(msg);
                    ws.send(msg);
                }
                remove();
            });
            box.options[i].name = ms;
        }
        box.show(scene,eye_controler);

        box.updatePosition(hc);

        if (data.title != ""){
            var l = box.options.length;
            var p, r,index;
            if ((l%2)==0) {
                index = l/2;
                p = {
                    x:(box.options[index].position.x + box.options[index-1].position.x)/2,
                    y:(box.options[index].position.y + box.options[index-1].position.y)/2,
                    z:(box.options[index].position.z + box.options[index-1].position.z)/2
                };
                r = box.options[index].rotation;
            } else {
                index = (l-1)/2;
                p = box.options[index].position;
                r = box.options[index].rotation;
            }
            var textMaterial = new THREE.MultiMaterial( [
                new THREE.MeshPhongMaterial( { color: 0x000000, shading: THREE.FlatShading } ), // front
                new THREE.MeshPhongMaterial( { color: 0xffffff, shading: THREE.SmoothShading } ) // side
            ] );
            var textGeo = new THREE.TextGeometry( data.title, {
                font: font,
                size: 50,
                height: 20,
                curveSegments: 4,
                bevelThickness: 2,
                bevelSize: 1.5,
                bevelEnabled: true,
                material: 0,
                extrudeMaterial: 1
            });
            textGeo.computeBoundingBox();
            textGeo.computeVertexNormals();
            var centerOffset = -0.5 * ( textGeo.boundingBox.max.x - textGeo.boundingBox.min.x );

            textMesh = new THREE.Mesh( textGeo, textMaterial );
            textMesh.position.x = centerOffset + p.x;
            textMesh.position.y = p.y+50;
            textMesh.position.z = p.z;
            textMesh.rotation.x = r.x;
            textMesh.rotation.y = r.y;
            textMesh.rotation.z = r.z;

            scene.add(textMesh);
        }

    }

    function changeVideo(src) {
        var video_status = 0;
        var tmpMesh;
        var tmpVideo = document.createElement( 'video' );
        tmpVideo.src = src;
        tmpVideo.setAttribute('crossorigin', 'anonymous');
        tmpVideo.setAttribute( 'webkit-playsinline', 'webkit-playsinline' );
        tmpVideo.load();
        tmpVideo.play();
        (function(){
            if (video_status != 1){
                video_status = 1;
                var light_status = 0;
                function black(color){
                    color = (color - 2) /255;
                    ambientLight.color.setRGB(color,color,color);
                }
                function light(color) {
                    color = (color + 2) /255;
                    ambientLight.color.setRGB(color,color,color);
                }
                function showVideo() {



                    var tmpTexture = new THREE.VideoTexture( tmpVideo );
                    tmpTexture.minFilter = THREE.NearestFilter;
                    tmpTexture.maxFilter = THREE.NearestFilter;
                    tmpTexture.format = THREE.RGBFormat;
                    tmpTexture.generateMipmaps = false;

                    var tmpGeometry = new THREE.SphereBufferGeometry( 400, 60, 40 ).toNonIndexed();
                    tmpGeometry.scale( - 1, 1, 1 );
                    var tmpMaterial = new THREE.MeshBasicMaterial( { map: tmpTexture } );
                    tmpMesh = new THREE.Mesh( get_geometry(), tmpMaterial );
                    scene.add( tmpMesh );
                }
                function preDelVideo() {
                    light_status=3;
                    requestAnimationFrame(handler);
                }
                function delVideo() {
                    scene.remove( tmpMesh );
                }
                tmpVideo.addEventListener('ended',function(){
                    preDelVideo();
                });
                var handler = function(){
                    var color = ambientLight.color.r * 255;
                    if (light_status == 0) {
                        if (color > 10) {
                            black(color);
                            requestAnimationFrame(handler);
                        } else {
                            ambientLight.color.setRGB(0,0,0);
                            showVideo();
                            light_status++;
                            requestAnimationFrame(handler);
                        }
                    } else if (light_status == 1) {
                        if (color < 245) {
                            light(color);
                            requestAnimationFrame(handler);
                        } else {
                            ambientLight.color.set(0xffffff);
                            light_status++;
                        }
                    } else if (light_status == 3) {
                        if (color > 10) {
                            black(color);
                            requestAnimationFrame(handler);
                        } else {
                            ambientLight.color.setRGB(0,0,0);
                            delVideo();
                            light_status++;
                            requestAnimationFrame(handler);
                        }
                    } else if (light_status == 4) {
                        if (color < 245) {
                            light(color);
                            requestAnimationFrame(handler);
                        } else {
                            ambientLight.color.set(0xffffff);
                            light_status = 0;
                            video_status = 0;
                        }
                    }
                };
                handler();
            }

        })();

    }

    function animate() {

        render();
        requestAnimationFrame( animate );

    }

    function render() {

        controls.update();
        menu.update(hc);
        eye_controler.update();
        effect.render( scene, camera );

    }

    function cv_found() {
        cv.hide_cursor(scene);
    }


    function get_geometry() {
        var geometry = new THREE.SphereBufferGeometry( 500, 60, 40 ).toNonIndexed();
        geometry.scale( - 1, 1, 1 );

        // Remap UVs

//        var normals = geometry.attributes.normal.array;
//        var uvs = geometry.attributes.uv.array;
//
//        for ( var i = 0, l = normals.length / 3; i < l; i ++ ) {
//
//            var x = normals[ i * 3 + 0 ];
//            var y = normals[ i * 3 + 1 ];
//            var z = normals[ i * 3 + 2 ];
//
//            if ( i < l / 2 ) {
//
//                var correction = ( x == 0 && z == 0 ) ? 1 : ( Math.acos( y ) / Math.sqrt( x * x + z * z ) ) * ( 2 / Math.PI );
//                uvs[ i * 2 + 0 ] = x * ( 404 / 1920 ) * correction + ( 447 / 1920 );
//                uvs[ i * 2 + 1 ] = z * ( 404 / 1080 ) * correction + ( 582 / 1080 );
//
//            } else {
//
//                var correction = ( x == 0 && z == 0 ) ? 1 : ( Math.acos( - y ) / Math.sqrt( x * x + z * z ) ) * ( 2 / Math.PI );
//                uvs[ i * 2 + 0 ] = - x * ( 404 / 1920 ) * correction + ( 1460 / 1920 );
//                uvs[ i * 2 + 1 ] = z * ( 404 / 1080 ) * correction + ( 582 / 1080 );
//
//            }
//
//        }

        //geometry.rotateZ(  Math.PI / 2 );

        return geometry;
        //
    }

</script>
<script>
// These will be initialized later
var recognizer, recorder, callbackManager, audioContext, outputContainer;
// Only when both recorder and recognizer do we have a ready application
var isRecorderReady = isRecognizerReady = false;

// A convenience function to post a message to the recognizer and associate
// a callback to its response
function postRecognizerJob(message, callback) {
	var msg = message || {};
	if (callbackManager) msg.callbackId = callbackManager.add(callback);
	if (recognizer) recognizer.postMessage(msg);
};

// This function initializes an instance of the recorder
// it posts a message right away and calls onReady when it
// is ready so that onmessage can be properly set
function spawnWorker(workerURL, onReady) {
	recognizer = new Worker(workerURL);
	recognizer.onmessage = function(event) {
		onReady(recognizer);
	};
	// Notice that we pass the name of the pocketsphinx.js file to load
	// as we need the file packaged with the Chinese acoustic model
	recognizer.postMessage('pocketsphinx_zh.js');
};

// To display the hypothesis sent by the recognizer
function updateHyp(hyp) {
	switch(hyp){
		case '送鲜花':
			texiao1();
			break;
		case '送邮轮':
			texiao();
            break;
        case '点个赞':
            zan(10);
            break;
		default:
			break;
	}
};

function checkLunch() {
	if (isRecorderReady && isRecognizerReady){
		recorder && recorder.start(0)
	}
};

// This is just a logging window where we display the status
function updateStatus(newStatus) {
	//document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
};

// Callback function once the user authorises access to the microphone
// in it, we instanciate the recorder
function startUserMedia(stream) {
	var input = audioContext.createMediaStreamSource(stream);
	// Firefox hack https://support.mozilla.org/en-US/questions/984179
	window.firefox_audio_hack = input;
	// Notice that for this Chinese acoustic model, audio must be at 8kHz, so we should
	// request it from the recorder
	var audioRecorderConfig = {
errorCallback: function(x) {updateStatus("Error from recorder: " + x);},
	       outputSampleRate: 8000
	};
	recorder = new AudioRecorder(input, audioRecorderConfig);
	// If a recognizer is ready, we pass it to the recorder
	if (recognizer) recorder.consumers = [recognizer];
	isRecorderReady = true;
	checkLunch();
	updateStatus("Audio recorder ready");
};

// Called once the recognizer is ready
// We then add the grammars to the input select tag and update the UI
var recognizerReady = function() {
	isRecognizerReady = true;
	checkLunch();
	updateStatus("Recognizer ready");
};

// This adds a grammar from the grammars array
// We add them one by one and call it again as
// a callback.
// Once we are done adding all grammars, we can call
// recognizerReady()
var feedGrammar = function(g, index, id) {
	if (id && (grammarIds.length > 0)) grammarIds[0].id = id.id;
	if (index < g.length) {
		grammarIds.unshift({title: g[index].title})
			postRecognizerJob({command: 'addGrammar', data: g[index].g},
					function(id) {feedGrammar(grammars, index + 1, {id:id});});
	} else {
		recognizerReady();
	}
};

// This adds words to the recognizer. When it calls back, we add grammars
var feedWords = function(words) {
	postRecognizerJob({command: 'addWords', data: words},
			function() {feedGrammar(grammars, 0);});
};

// This initializes the recognizer. When it calls back, we add words
var initRecognizer = function() {
	// You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
	// Pay attention here to state the sample rate as the default value is 16kHz and this Chinese acoustic model uses 8kHz
	postRecognizerJob({command: 'initialize', data:[["-samprate", "8000"]]},
			function() {
			if (recorder) recorder.consumers = [recognizer];
			feedWords(wordList);});
};

function open_voice() {
    outputContainer = document.getElementById("output");
    updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");
    callbackManager = new CallbackManager();
    spawnWorker("js/recognizer.js", function(worker) {
        // This is the onmessage function, once the worker is fully loaded
        worker.onmessage = function(e) {
            // This is the case when we have a callback id to be called
            if (e.data.hasOwnProperty('id')) {
                var clb = callbackManager.get(e.data['id']);
                var data = {};
                if ( e.data.hasOwnProperty('data')) data = e.data.data;
                if(clb) clb(data);
            }
            // This is a case when the recognizer has a new hypothesis
            // Notice that pocketsphinx.js does not yet recognize words
            // encoded in UTF8, so we map them to ASCII strings. Here we
            // display both ASCII and Chinese strings
            if (e.data.hasOwnProperty('hyp')) {
                console.log(e.data.hyp);
                var hyparray = e.data.hyp.split(' ');
                if(hyparray[hypNum] != '' && hyparray.length>hypNum){
                    var newHyp = hyparray[hypNum];
                    hypNum++;
                    var newHypChinese = wordListChinese[newHyp];
                    updateHyp(newHypChinese);
                }
            }
            // This is the case when we have an error
            if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                updateStatus("Error in " + e.data.command + " with code " + e.data.code);
            }
        };
        // Once the worker is fully loaded, we can call the initialize function
        initRecognizer();
    });

    // The following is to initialize Web Audio
    try {
        window.AudioContext = window.AudioContext || window.webkitAudioContext;
        navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
        window.URL = window.URL || window.webkitURL;
        audioContext = new AudioContext();
    } catch (e) {
        updateStatus("Error initializing Web Audio browser");
    }
    if (navigator.getUserMedia) navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
        updateStatus("No live audio input in this browser");
    });
    else updateStatus("No web audio support in this browser");
}
// When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
// request access to the microphone
window.onload = function() {
    //init WebSocket
    if (ws) {
        return false;
    }
    ws = new WebSocket('wss://10.235.24.45:8087/user');
    console.log(ws);
    ws.onopen = function(evt) {
        console.log("WebSocket open");
    };
    ws.onclose = function(evt) {
        console.log("WebSocket close");
        ws = null;
    };
    ws.onmessage = function(evt) {
        var data = JSON.parse(evt.data);
        console.log(data);
        if (data.type == "video"){
            changeVideo(data.data);
        } else if(data.type == "menu") {
            addBox(data.data);
        } else if(data.type == "item") {
            placeItem(data.data);
        } else if(data.type == "music") {
            playAudio(data.data);
        } else if(data.type == "uid") {
            user = data.data;
        } else if(data.type == "delitem") {
            delItem(data);
        } else if(data.type == "headmenu") {
            head(data.data);
        } else if(data.type == "tips") {
            showTips(data.data);
        }

    };
    ws.onerror = function(evt) {
        console.log("WebSocket error");
        console.log(evt);
    };

};

// This is the list of words that need to be added to the recognizer
// This follows the CMU dictionary format and the phone set of the Chinese model
// These words were taken from model/lm/zh_CN/mandarin_notone.dic
var wordList = [["dian_ge_zan","d i an g e z an"], ["song_you_lun", "s ong y ou l un"], ["song_xian_hua", "s ong x i an h ua"]];
var wordListChinese = {"dian_ge_zan": "点个赞", "song_you_lun": "送邮轮", "song_xian_hua": "送鲜花"};
var grammarChineseGreetings = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "dian_ge_zan"},{from: 0, to: 0, word: "song_you_lun"},{from: 0, to: 0, word: "song_xian_hua"}]};
var grammars = [{title: "Chinese Greetings", g: grammarChineseGreetings}];
var grammarIds = [];
var hypNum = 0;
</script>
<!-- These are the two JavaScript files you must load in the HTML,
    The recognizer is loaded through a Web Worker -->
<script src="js/audioRecorder.js"></script>
<script src="js/callbackManager.js"></script>
</body>
</html>
